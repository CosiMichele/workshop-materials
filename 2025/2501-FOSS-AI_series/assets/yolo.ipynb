{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 ######################\n",
    "# Create python environment\n",
    "# !python -m venv yolo\n",
    "# !pip install torch numpy notebook ipykernel opencv-python\n",
    "# !python3 -m ipykernel install --name \"yolo\" --user\n",
    "# !sudo apt-get install vlc\n",
    "# 2 ######################\n",
    "# !pip install ultralytics\n",
    "# or\n",
    "# !conda create -n yolo\n",
    "# !conda activate yolo\n",
    "# !conda install -c conda-forge ultralytics\n",
    "# 2 ######################\n",
    "# Download yolo11 detection from here: https://docs.ultralytics.com/models/yolo11/#supported-tasks-and-modes\n",
    "# !wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt\n",
    "# 3 ######################\n",
    "# Download bean data\n",
    "# 3.1 Go to https://universe.roboflow.com/test-fdsxz/beans-dijdm/dataset/1\n",
    "# 3.2 Login \n",
    "# 3.3 Download txt for yolo11\n",
    "# 4 ######################\n",
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Setup Environment\n",
    "\n",
    "```\n",
    "python -m venv yolo\n",
    "source yolo/bin/activate\n",
    "pip install torch numpy notebook ipykernel opencv-python numpy ultralytics\n",
    "python3 -m ipykernel install --name \"yolo\" --user\n",
    "sudo apt-get install vlc\n",
    "wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt\n",
    "```\n",
    "\n",
    "### 2. Images with Roboflow\n",
    "\n",
    "- Go to: https://universe.roboflow.com/test-fdsxz/beans-dijdm/dataset/1\n",
    "- Log in and click \"download YOLOv11\"\n",
    "  - Download dataset\n",
    "  - YOLOv11 format\n",
    "  - Download zip to computer\n",
    "- Decompress with `unzip <file.zip>`\n",
    "- `cd` into folder\n",
    "  \n",
    "### 3. Train YOLO\n",
    "\n",
    "- Train YOLO with `yolo detect train data=data.yaml model=yolo11n.pt epochs=100 imgsz=640`\n",
    "- `cp runs/detect/train3/weights/best.pt ~/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable code: Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Path to input video\n",
    "video_path = r\"1135446.mp4\"\n",
    "\n",
    "# Open video stream\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Read the first frame\n",
    "success, img = cap.read()\n",
    "\n",
    "if success:\n",
    "    # Process the frame\n",
    "    result_img, _ = predict_and_detect(model, img, classes=[], conf=0.5)\n",
    "    \n",
    "    # Save the processed image\n",
    "    output_image_filename = \"output_image.jpg\"\n",
    "    cv2.imwrite(output_image_filename, result_img)\n",
    "    print(f\"Saved: {output_image_filename}\")\n",
    "else:\n",
    "    print(\"Failed to read the video file.\")\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable code: Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#OVERVIEW: The yolo model detects objects in a single frame, these detections are used to draw the actual boxes on top of the input frame\n",
    "#          and write them to a new mp4 file. Rinse and repeat for the entire input video\n",
    "\n",
    "#Branches yolos predict method based on weather classes are provided\n",
    "def predict(chosen_model, img, classes=[], conf=0.5):\n",
    "    if classes:\n",
    "        results = chosen_model.predict(img, classes=classes, conf=conf)\n",
    "    else:\n",
    "        results = chosen_model.predict(img, conf=conf)\n",
    "\n",
    "    #results are a list of attributes like boxes, masks, etc https://docs.ultralytics.com/modes/predict/#working-with-results\n",
    "    return results\n",
    "\n",
    "def predict_and_detect(chosen_model, img, classes=[], conf=0.5, rectangle_thickness=2, text_thickness=1):\n",
    "    results = predict(chosen_model, img, classes, conf=conf)\n",
    "    #count variable keeps track of total objects detected by the model (optional functionality)\n",
    "    count=0\n",
    "    \n",
    "    #for each individual detection, draw a rectangle bounding box and title of the detected object\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "\n",
    "            #rectangle method needs coordinates of the two corners of the rectangle you need drawn\n",
    "            #https://www.geeksforgeeks.org/python-opencv-cv2-rectangle-method/\n",
    "            #box.xyxy holds pixel coordinates in a 2d list and are used as points to draw the rectangle\n",
    "            cv2.rectangle(img, (int(box.xyxy[0][0]), int(box.xyxy[0][1])),\n",
    "                          (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (255, 0, 0), rectangle_thickness)\n",
    "            \n",
    "            #Create text above the generated box that prints the class name\n",
    "            cv2.putText(img, f\"{result.names[int(box.cls[0])]}\",\n",
    "                        (int(box.xyxy[0][0]), int(box.xyxy[0][1]) - 10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), text_thickness)\n",
    "            count += 1\n",
    "\n",
    "    #creates box and text in output image displaying the total cow count\n",
    "    cv2.rectangle(img, (10, 5), (165, 50), (0,0,0), -1)\n",
    "    cv2.putText(img, f\"BEANS: {count}\", (10,35), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "\n",
    "    #return edited frame (img) containing bounding boxes\n",
    "    return img, results\n",
    "\n",
    "# defining function for creating a writer (for mp4 videos)\n",
    "def create_video_writer(video_cap, output_filename):\n",
    "\n",
    "    # grab the width, height, and fps of the frames in the video stream.\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # initialize the FourCC and a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V') #mp4 file format\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n",
    "                             (frame_width, frame_height))\n",
    "\n",
    "    #return writer has .write method to \"write\" individual frames of new video with bounding boxes, based on the info outlined above\n",
    "    return writer\n",
    "\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "output_filename = \"out.mp4\"\n",
    "\n",
    "video_path = r\"1135446.mp4\"\n",
    "\n",
    "#cv2 video stream to run the model against\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "writer = create_video_writer(cap, output_filename)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    #logic to end loop when video finishes\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    #get prcocessed frame and write it into output video file\n",
    "    result_img, _ = predict_and_detect(model, img, classes=[], conf=0.5)\n",
    "    writer.write(result_img)\n",
    "\n",
    "    #show live progress of video writing\n",
    "    cv2.imshow(\"Image\", result_img)\n",
    "    \n",
    "    cv2.waitKey(1)\n",
    "writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
